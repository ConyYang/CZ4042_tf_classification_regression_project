{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# scale data\n",
    "def scale(X, X_min, X_max):\n",
    "    return (X - X_min)/(X_max-X_min)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PartI : Read in the dataset. Check what the shape of dataset and what data contains.\n",
    "Separate the train and test dataset. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#read train data\n",
    "train_input = np.genfromtxt('ctg_data_cleaned.csv', delimiter= ',')\n",
    "trainX, train_Y = train_input[1:, :21], train_input[1:,-1].astype(int)\n",
    "trainX = scale(trainX, np.min(trainX, axis=0), np.max(trainX, axis=0))\n",
    "trainY = train_Y-1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.25925926 0.         0.         0.         0.         0.\n",
      "  0.         0.81333333 0.04411765 0.47252747 0.04733728 0.34463277\n",
      "  0.11009174 0.03448276 0.11111111 0.         0.47244094 0.58715596\n",
      "  0.40366972 0.27137546 1.        ]]\n",
      "(2126, 21)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(trainX[:1])\n",
    "print(trainX.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1 0 0 0 0 2 2 2 2 2]\n",
      "(2126,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(trainY[:10])\n",
    "print(trainY.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(1488, 21)\n",
      "(1488,)\n",
      "(638, 21)\n",
      "(638,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# divide the dataset in 70:30 ratio for training and testing\n",
    "X_train = trainX[:1488]\n",
    "y_train = trainY[:1488]\n",
    "X_test = trainX[-638:]\n",
    "y_test = trainY[-638:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PartII: Design the neural network\n",
    "Design a feedforward neural network which consists of an input layer, \n",
    "one hidden layer of 10 neurons with ReLU activation function, \n",
    "and an output softmax layer. \n",
    "Assume a learning rate ùõº = 0.01, \n",
    "L2 regularization with weight decay parameter ùõΩ = 10‚àí6, \n",
    "and batch size = 32. \n",
    "Use appropriate scaling of input features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "num_neurons = 10\n",
    "seed = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.layers.Dense(num_neurons, activation='relu'),\n",
    "#     keras.layers.Dense(NUM_CLASSES)\n",
    "# ])\n",
    "def build_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=21, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    # Compile model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.01,\n",
    "                                       beta_1=0.9,\n",
    "                                       beta_2=0.999,\n",
    "                                       epsilon=1e-07,\n",
    "                                       amsgrad=False)\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#complie the model use K-th folder validation\n",
    "k = 5\n",
    "num_val_samples = len(trainX)//k\n",
    "all_scores = []\n",
    "histories_acc = []\n",
    "histories_loss = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class TestCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "\n",
      "Testing loss: 0.7446687817573547, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8280 - accuracy: 0.8136\n",
      "Epoch 2/100\n",
      "\n",
      "Testing loss: 0.7235260605812073, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7373 - accuracy: 0.8289\n",
      "Epoch 3/100\n",
      "\n",
      "Testing loss: 0.7188014388084412, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7257 - accuracy: 0.8289\n",
      "Epoch 4/100\n",
      "\n",
      "Testing loss: 0.7178393602371216, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7231 - accuracy: 0.8289\n",
      "Epoch 5/100\n",
      "\n",
      "Testing loss: 0.7176607251167297, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7227 - accuracy: 0.8289\n",
      "Epoch 6/100\n",
      "\n",
      "Testing loss: 0.7176218628883362, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7226 - accuracy: 0.8289\n",
      "Epoch 7/100\n",
      "\n",
      "Testing loss: 0.7176092267036438, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 8/100\n",
      "\n",
      "Testing loss: 0.7176030874252319, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 9/100\n",
      "\n",
      "Testing loss: 0.7175995707511902, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 10/100\n",
      "\n",
      "Testing loss: 0.717597246170044, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 11/100\n",
      "\n",
      "Testing loss: 0.7175957560539246, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 12/100\n",
      "\n",
      "Testing loss: 0.717594563961029, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 13/100\n",
      "\n",
      "Testing loss: 0.7175936698913574, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 14/100\n",
      "\n",
      "Testing loss: 0.7175929546356201, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 15/100\n",
      "\n",
      "Testing loss: 0.7175923585891724, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 16/100\n",
      "\n",
      "Testing loss: 0.7175918817520142, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 17/100\n",
      "\n",
      "Testing loss: 0.7175916433334351, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 18/100\n",
      "\n",
      "Testing loss: 0.7175912857055664, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 19/100\n",
      "\n",
      "Testing loss: 0.7175909876823425, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 20/100\n",
      "\n",
      "Testing loss: 0.7175908088684082, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 21/100\n",
      "\n",
      "Testing loss: 0.7175906300544739, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 22/100\n",
      "\n",
      "Testing loss: 0.7175905108451843, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 23/100\n",
      "\n",
      "Testing loss: 0.7175903916358948, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 24/100\n",
      "\n",
      "Testing loss: 0.71759033203125, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 25/100\n",
      "\n",
      "Testing loss: 0.7175900936126709, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 26/100\n",
      "\n",
      "Testing loss: 0.7175900340080261, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 27/100\n",
      "\n",
      "Testing loss: 0.7175899744033813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 28/100\n",
      "\n",
      "Testing loss: 0.7175899744033813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 29/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 30/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 31/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 32/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 33/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 34/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 35/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 36/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 37/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 38/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 39/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 40/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 41/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 42/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 43/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 44/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 45/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 46/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 47/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 48/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 49/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 50/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 51/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 52/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 53/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 54/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 55/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 56/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 57/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 58/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 59/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 60/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 61/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 62/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 63/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 64/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 65/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 66/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 67/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 68/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 69/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 70/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 71/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 72/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 73/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 74/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 75/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 76/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 77/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 78/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 79/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 80/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 81/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 82/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 83/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 84/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 85/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 86/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 87/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 88/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 89/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 90/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 91/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 92/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 93/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 94/100\n",
      "\n",
      "Testing loss: 0.7175890207290649, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 95/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 96/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 97/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 98/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 99/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "Epoch 100/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7225 - accuracy: 0.8289\n",
      "14/14 - 0s - loss: 0.9750 - accuracy: 0.5765\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "\n",
      "Testing loss: 0.7489601373672485, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.9055 - accuracy: 0.7501\n",
      "Epoch 2/100\n",
      "\n",
      "Testing loss: 0.7270054221153259, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7624 - accuracy: 0.8089\n",
      "Epoch 3/100\n",
      "\n",
      "Testing loss: 0.7211471796035767, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7495 - accuracy: 0.8089\n",
      "Epoch 4/100\n",
      "\n",
      "Testing loss: 0.7189724445343018, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7451 - accuracy: 0.8089\n",
      "Epoch 5/100\n",
      "\n",
      "Testing loss: 0.7181953191757202, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7435 - accuracy: 0.8089\n",
      "Epoch 6/100\n",
      "\n",
      "Testing loss: 0.7178964614868164, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7430 - accuracy: 0.8089\n",
      "Epoch 7/100\n",
      "\n",
      "Testing loss: 0.7177689075469971, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7428 - accuracy: 0.8089\n",
      "Epoch 8/100\n",
      "\n",
      "Testing loss: 0.7177076935768127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7427 - accuracy: 0.8089\n",
      "Epoch 9/100\n",
      "\n",
      "Testing loss: 0.7176733016967773, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7426 - accuracy: 0.8089\n",
      "Epoch 10/100\n",
      "\n",
      "Testing loss: 0.717652440071106, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7426 - accuracy: 0.8089\n",
      "Epoch 11/100\n",
      "\n",
      "Testing loss: 0.7176382541656494, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7426 - accuracy: 0.8089\n",
      "Epoch 12/100\n",
      "\n",
      "Testing loss: 0.7176283597946167, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7426 - accuracy: 0.8089\n",
      "Epoch 13/100\n",
      "\n",
      "Testing loss: 0.7176214456558228, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 14/100\n",
      "\n",
      "Testing loss: 0.7176161408424377, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 15/100\n",
      "\n",
      "Testing loss: 0.717612087726593, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 16/100\n",
      "\n",
      "Testing loss: 0.7176088690757751, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 17/100\n",
      "\n",
      "Testing loss: 0.7176061868667603, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 18/100\n",
      "\n",
      "Testing loss: 0.7176042795181274, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 19/100\n",
      "\n",
      "Testing loss: 0.7176024317741394, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 20/100\n",
      "\n",
      "Testing loss: 0.7176010012626648, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 21/100\n",
      "\n",
      "Testing loss: 0.7175997495651245, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 22/100\n",
      "\n",
      "Testing loss: 0.7175987362861633, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 23/100\n",
      "\n",
      "Testing loss: 0.7175978422164917, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 24/100\n",
      "\n",
      "Testing loss: 0.7175971269607544, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 25/100\n",
      "\n",
      "Testing loss: 0.7175964117050171, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 26/100\n",
      "\n",
      "Testing loss: 0.7175957560539246, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 27/100\n",
      "\n",
      "Testing loss: 0.7175952792167664, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 28/100\n",
      "\n",
      "Testing loss: 0.7175947427749634, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 29/100\n",
      "\n",
      "Testing loss: 0.71759432554245, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 30/100\n",
      "\n",
      "Testing loss: 0.7175939679145813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 31/100\n",
      "\n",
      "Testing loss: 0.7175935506820679, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 32/100\n",
      "\n",
      "Testing loss: 0.7175933122634888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 33/100\n",
      "\n",
      "Testing loss: 0.7175929546356201, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 34/100\n",
      "\n",
      "Testing loss: 0.7175927758216858, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 35/100\n",
      "\n",
      "Testing loss: 0.7175925374031067, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 36/100\n",
      "\n",
      "Testing loss: 0.717592179775238, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 37/100\n",
      "\n",
      "Testing loss: 0.7175920009613037, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 38/100\n",
      "\n",
      "Testing loss: 0.7175918817520142, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 39/100\n",
      "\n",
      "Testing loss: 0.7175917625427246, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 40/100\n",
      "\n",
      "Testing loss: 0.7175914645195007, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 41/100\n",
      "\n",
      "Testing loss: 0.717591404914856, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 42/100\n",
      "\n",
      "Testing loss: 0.7175912857055664, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 43/100\n",
      "\n",
      "Testing loss: 0.7175911664962769, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 44/100\n",
      "\n",
      "Testing loss: 0.7175910472869873, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 45/100\n",
      "\n",
      "Testing loss: 0.7175909280776978, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 46/100\n",
      "\n",
      "Testing loss: 0.717590868473053, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 47/100\n",
      "\n",
      "Testing loss: 0.7175909280776978, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 48/100\n",
      "\n",
      "Testing loss: 0.7175907492637634, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 49/100\n",
      "\n",
      "Testing loss: 0.7175906896591187, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 50/100\n",
      "\n",
      "Testing loss: 0.7175904512405396, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 51/100\n",
      "\n",
      "Testing loss: 0.7175904512405396, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 52/100\n",
      "\n",
      "Testing loss: 0.7175902724266052, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 53/100\n",
      "\n",
      "Testing loss: 0.7175902724266052, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 54/100\n",
      "\n",
      "Testing loss: 0.7175902128219604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 55/100\n",
      "\n",
      "Testing loss: 0.7175902128219604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 56/100\n",
      "\n",
      "Testing loss: 0.7175902128219604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 57/100\n",
      "\n",
      "Testing loss: 0.7175900936126709, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 58/100\n",
      "\n",
      "Testing loss: 0.7175900936126709, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 59/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 60/100\n",
      "\n",
      "Testing loss: 0.7175899744033813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 61/100\n",
      "\n",
      "Testing loss: 0.717589795589447, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 62/100\n",
      "\n",
      "Testing loss: 0.717589795589447, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 63/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 64/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 65/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 66/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 67/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 68/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 69/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 70/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 71/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 72/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 73/100\n",
      "\n",
      "Testing loss: 0.7175895571708679, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 74/100\n",
      "\n",
      "Testing loss: 0.7175895571708679, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 75/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 76/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 77/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 78/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 79/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 80/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 81/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 82/100\n",
      "\n",
      "Testing loss: 0.7175894379615784, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 83/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 84/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 85/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 86/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 87/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 88/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 89/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 90/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 91/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 92/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 93/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 94/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 95/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 96/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 97/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 98/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 99/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "Epoch 100/100\n",
      "\n",
      "Testing loss: 0.7175890803337097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7425 - accuracy: 0.8089\n",
      "14/14 - 0s - loss: 0.8950 - accuracy: 0.6565\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "\n",
      "Testing loss: 0.7455825805664062, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.9519 - accuracy: 0.6855\n",
      "Epoch 2/100\n",
      "\n",
      "Testing loss: 0.7287489771842957, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8395 - accuracy: 0.7284\n",
      "Epoch 3/100\n",
      "\n",
      "Testing loss: 0.7238785028457642, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8304 - accuracy: 0.7284\n",
      "Epoch 4/100\n",
      "\n",
      "Testing loss: 0.7214484810829163, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8271 - accuracy: 0.7284\n",
      "Epoch 5/100\n",
      "\n",
      "Testing loss: 0.7199671864509583, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8255 - accuracy: 0.7284\n",
      "Epoch 6/100\n",
      "\n",
      "Testing loss: 0.7190503478050232, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8245 - accuracy: 0.7284\n",
      "Epoch 7/100\n",
      "\n",
      "Testing loss: 0.7185444831848145, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8239 - accuracy: 0.7284\n",
      "Epoch 8/100\n",
      "\n",
      "Testing loss: 0.7182192206382751, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8236 - accuracy: 0.7284\n",
      "Epoch 9/100\n",
      "\n",
      "Testing loss: 0.7180242538452148, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8234 - accuracy: 0.7284\n",
      "Epoch 10/100\n",
      "\n",
      "Testing loss: 0.717913031578064, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8233 - accuracy: 0.7284\n",
      "Epoch 11/100\n",
      "\n",
      "Testing loss: 0.7178307175636292, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8232 - accuracy: 0.7284\n",
      "Epoch 12/100\n",
      "\n",
      "Testing loss: 0.7177756428718567, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8232 - accuracy: 0.7284\n",
      "Epoch 13/100\n",
      "\n",
      "Testing loss: 0.7177366018295288, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8232 - accuracy: 0.7284\n",
      "Epoch 14/100\n",
      "\n",
      "Testing loss: 0.71770840883255, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 15/100\n",
      "\n",
      "Testing loss: 0.7176878452301025, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 16/100\n",
      "\n",
      "Testing loss: 0.7176722288131714, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 17/100\n",
      "\n",
      "Testing loss: 0.7176598310470581, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 18/100\n",
      "\n",
      "Testing loss: 0.7176503539085388, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 19/100\n",
      "\n",
      "Testing loss: 0.7176424860954285, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 20/100\n",
      "\n",
      "Testing loss: 0.7176359295845032, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 21/100\n",
      "\n",
      "Testing loss: 0.7176306843757629, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 22/100\n",
      "\n",
      "Testing loss: 0.7176260948181152, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 23/100\n",
      "\n",
      "Testing loss: 0.7176224589347839, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 24/100\n",
      "\n",
      "Testing loss: 0.7176190614700317, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 25/100\n",
      "\n",
      "Testing loss: 0.7176161408424377, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 26/100\n",
      "\n",
      "Testing loss: 0.7176138162612915, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 27/100\n",
      "\n",
      "Testing loss: 0.71761155128479, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "\n",
      "Testing loss: 0.717609703540802, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 29/100\n",
      "\n",
      "Testing loss: 0.7176081538200378, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 30/100\n",
      "\n",
      "Testing loss: 0.7176065444946289, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 31/100\n",
      "\n",
      "Testing loss: 0.7176052927970886, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 32/100\n",
      "\n",
      "Testing loss: 0.7176041603088379, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 33/100\n",
      "\n",
      "Testing loss: 0.7176030278205872, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 34/100\n",
      "\n",
      "Testing loss: 0.7176020741462708, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 35/100\n",
      "\n",
      "Testing loss: 0.7176012992858887, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 36/100\n",
      "\n",
      "Testing loss: 0.717600405216217, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 37/100\n",
      "\n",
      "Testing loss: 0.7175997495651245, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 38/100\n",
      "\n",
      "Testing loss: 0.7175989747047424, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 39/100\n",
      "\n",
      "Testing loss: 0.7175984978675842, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 40/100\n",
      "\n",
      "Testing loss: 0.7175979614257812, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 41/100\n",
      "\n",
      "Testing loss: 0.7175974249839783, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 42/100\n",
      "\n",
      "Testing loss: 0.7175969481468201, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 43/100\n",
      "\n",
      "Testing loss: 0.7175965309143066, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 44/100\n",
      "\n",
      "Testing loss: 0.7175959944725037, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 45/100\n",
      "\n",
      "Testing loss: 0.7175957560539246, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 46/100\n",
      "\n",
      "Testing loss: 0.7175952792167664, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 47/100\n",
      "\n",
      "Testing loss: 0.7175950407981873, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 48/100\n",
      "\n",
      "Testing loss: 0.717594563961029, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 49/100\n",
      "\n",
      "Testing loss: 0.7175943851470947, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 50/100\n",
      "\n",
      "Testing loss: 0.7175940871238708, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 51/100\n",
      "\n",
      "Testing loss: 0.7175939083099365, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 52/100\n",
      "\n",
      "Testing loss: 0.7175936698913574, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 53/100\n",
      "\n",
      "Testing loss: 0.7175934910774231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 54/100\n",
      "\n",
      "Testing loss: 0.717593252658844, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 55/100\n",
      "\n",
      "Testing loss: 0.7175930738449097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 56/100\n",
      "\n",
      "Testing loss: 0.7175928950309753, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 57/100\n",
      "\n",
      "Testing loss: 0.7175928354263306, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 58/100\n",
      "\n",
      "Testing loss: 0.7175926566123962, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 59/100\n",
      "\n",
      "Testing loss: 0.7175922393798828, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 60/100\n",
      "\n",
      "Testing loss: 0.717592179775238, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 61/100\n",
      "\n",
      "Testing loss: 0.7175921201705933, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 62/100\n",
      "\n",
      "Testing loss: 0.7175918817520142, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 63/100\n",
      "\n",
      "Testing loss: 0.7175918817520142, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 64/100\n",
      "\n",
      "Testing loss: 0.7175916433334351, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 65/100\n",
      "\n",
      "Testing loss: 0.7175914645195007, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 66/100\n",
      "\n",
      "Testing loss: 0.7175914645195007, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 67/100\n",
      "\n",
      "Testing loss: 0.7175912857055664, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 68/100\n",
      "\n",
      "Testing loss: 0.7175912857055664, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 69/100\n",
      "\n",
      "Testing loss: 0.7175911664962769, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 70/100\n",
      "\n",
      "Testing loss: 0.7175912261009216, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 71/100\n",
      "\n",
      "Testing loss: 0.7175909280776978, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 72/100\n",
      "\n",
      "Testing loss: 0.7175909876823425, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 73/100\n",
      "\n",
      "Testing loss: 0.7175909280776978, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 74/100\n",
      "\n",
      "Testing loss: 0.7175908088684082, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 75/100\n",
      "\n",
      "Testing loss: 0.7175907492637634, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 76/100\n",
      "\n",
      "Testing loss: 0.7175907492637634, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 77/100\n",
      "\n",
      "Testing loss: 0.7175906896591187, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 78/100\n",
      "\n",
      "Testing loss: 0.7175905108451843, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 79/100\n",
      "\n",
      "Testing loss: 0.7175904512405396, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 80/100\n",
      "\n",
      "Testing loss: 0.71759033203125, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 81/100\n",
      "\n",
      "Testing loss: 0.71759033203125, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 82/100\n",
      "\n",
      "Testing loss: 0.7175902724266052, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 83/100\n",
      "\n",
      "Testing loss: 0.7175902128219604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 84/100\n",
      "\n",
      "Testing loss: 0.7175902128219604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 85/100\n",
      "\n",
      "Testing loss: 0.7175902128219604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 86/100\n",
      "\n",
      "Testing loss: 0.7175900936126709, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 87/100\n",
      "\n",
      "Testing loss: 0.7175900936126709, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 88/100\n",
      "\n",
      "Testing loss: 0.7175899744033813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 89/100\n",
      "\n",
      "Testing loss: 0.7175900340080261, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 90/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 91/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 92/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 93/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 94/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 95/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 96/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 97/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 98/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 99/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "Epoch 100/100\n",
      "\n",
      "Testing loss: 0.7175896763801575, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8231 - accuracy: 0.7284\n",
      "14/14 - 0s - loss: 0.5726 - accuracy: 0.9788\n",
      "processing fold # 3\n",
      "Epoch 1/100\n",
      "\n",
      "Testing loss: 0.7418688535690308, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.9029 - accuracy: 0.7302\n",
      "Epoch 2/100\n",
      "\n",
      "Testing loss: 0.6993758082389832, acc: 0.8793103694915771\n",
      "\n",
      "54/54 - 0s - loss: 0.8146 - accuracy: 0.7531\n",
      "Epoch 3/100\n",
      "\n",
      "Testing loss: 0.6730314493179321, acc: 0.9373040795326233\n",
      "\n",
      "54/54 - 0s - loss: 0.7947 - accuracy: 0.7819\n",
      "Epoch 4/100\n",
      "\n",
      "Testing loss: 0.6776111125946045, acc: 0.9467084407806396\n",
      "\n",
      "54/54 - 0s - loss: 0.7780 - accuracy: 0.8048\n",
      "Epoch 5/100\n",
      "\n",
      "Testing loss: 0.6715563535690308, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.7692 - accuracy: 0.8136\n",
      "Epoch 6/100\n",
      "\n",
      "Testing loss: 0.6767985820770264, acc: 0.92476487159729\n",
      "\n",
      "54/54 - 0s - loss: 0.7663 - accuracy: 0.8142\n",
      "Epoch 7/100\n",
      "\n",
      "Testing loss: 0.6842687129974365, acc: 0.9200627207756042\n",
      "\n",
      "54/54 - 0s - loss: 0.7614 - accuracy: 0.8160\n",
      "Epoch 8/100\n",
      "\n",
      "Testing loss: 0.6650108098983765, acc: 0.9341692924499512\n",
      "\n",
      "54/54 - 0s - loss: 0.7571 - accuracy: 0.8183\n",
      "Epoch 9/100\n",
      "\n",
      "Testing loss: 0.6917364001274109, acc: 0.9137930870056152\n",
      "\n",
      "54/54 - 0s - loss: 0.7540 - accuracy: 0.8248\n",
      "Epoch 10/100\n",
      "\n",
      "Testing loss: 0.6495367288589478, acc: 0.945141077041626\n",
      "\n",
      "54/54 - 0s - loss: 0.7562 - accuracy: 0.8219\n",
      "Epoch 11/100\n",
      "\n",
      "Testing loss: 0.6464424729347229, acc: 0.9514106512069702\n",
      "\n",
      "54/54 - 0s - loss: 0.7545 - accuracy: 0.8178\n",
      "Epoch 12/100\n",
      "\n",
      "Testing loss: 0.6613465547561646, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.7490 - accuracy: 0.8207\n",
      "Epoch 13/100\n",
      "\n",
      "Testing loss: 0.6735210418701172, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.7466 - accuracy: 0.8283\n",
      "Epoch 14/100\n",
      "\n",
      "Testing loss: 0.6964207291603088, acc: 0.9216300845146179\n",
      "\n",
      "54/54 - 0s - loss: 0.7404 - accuracy: 0.8383\n",
      "Epoch 15/100\n",
      "\n",
      "Testing loss: 0.7245302200317383, acc: 0.9043887257575989\n",
      "\n",
      "54/54 - 0s - loss: 0.7359 - accuracy: 0.8460\n",
      "Epoch 16/100\n",
      "\n",
      "Testing loss: 0.6560948491096497, acc: 0.945141077041626\n",
      "\n",
      "54/54 - 0s - loss: 0.7350 - accuracy: 0.8460\n",
      "Epoch 17/100\n",
      "\n",
      "Testing loss: 0.6830500364303589, acc: 0.9231975078582764\n",
      "\n",
      "54/54 - 0s - loss: 0.7327 - accuracy: 0.8448\n",
      "Epoch 18/100\n",
      "\n",
      "Testing loss: 0.6969417929649353, acc: 0.9169278740882874\n",
      "\n",
      "54/54 - 0s - loss: 0.7235 - accuracy: 0.8624\n",
      "Epoch 19/100\n",
      "\n",
      "Testing loss: 0.6642464399337769, acc: 0.9341692924499512\n",
      "\n",
      "54/54 - 0s - loss: 0.7261 - accuracy: 0.8654\n",
      "Epoch 20/100\n",
      "\n",
      "Testing loss: 0.6946049332618713, acc: 0.9028213024139404\n",
      "\n",
      "54/54 - 0s - loss: 0.7242 - accuracy: 0.8618\n",
      "Epoch 21/100\n",
      "\n",
      "Testing loss: 0.6778918504714966, acc: 0.92476487159729\n",
      "\n",
      "54/54 - 0s - loss: 0.7162 - accuracy: 0.8683\n",
      "Epoch 22/100\n",
      "\n",
      "Testing loss: 0.670265793800354, acc: 0.9278996586799622\n",
      "\n",
      "54/54 - 0s - loss: 0.7184 - accuracy: 0.8607\n",
      "Epoch 23/100\n",
      "\n",
      "Testing loss: 0.6591665148735046, acc: 0.9420062899589539\n",
      "\n",
      "54/54 - 0s - loss: 0.7159 - accuracy: 0.8654\n",
      "Epoch 24/100\n",
      "\n",
      "Testing loss: 0.663798987865448, acc: 0.9357366561889648\n",
      "\n",
      "54/54 - 0s - loss: 0.7179 - accuracy: 0.8630\n",
      "Epoch 25/100\n",
      "\n",
      "Testing loss: 0.685120701789856, acc: 0.9216300845146179\n",
      "\n",
      "54/54 - 0s - loss: 0.7146 - accuracy: 0.8701\n",
      "Epoch 26/100\n",
      "\n",
      "Testing loss: 0.6656454205513, acc: 0.931034505367279\n",
      "\n",
      "54/54 - 0s - loss: 0.7161 - accuracy: 0.8618\n",
      "Epoch 27/100\n",
      "\n",
      "Testing loss: 0.6773532629013062, acc: 0.9231975078582764\n",
      "\n",
      "54/54 - 0s - loss: 0.7129 - accuracy: 0.8683\n",
      "Epoch 28/100\n",
      "\n",
      "Testing loss: 0.6536958813667297, acc: 0.9420062899589539\n",
      "\n",
      "54/54 - 0s - loss: 0.7070 - accuracy: 0.8748\n",
      "Epoch 29/100\n",
      "\n",
      "Testing loss: 0.6680353879928589, acc: 0.9137930870056152\n",
      "\n",
      "54/54 - 0s - loss: 0.7078 - accuracy: 0.8695\n",
      "Epoch 30/100\n",
      "\n",
      "Testing loss: 0.6896868944168091, acc: 0.8965517282485962\n",
      "\n",
      "54/54 - 0s - loss: 0.7261 - accuracy: 0.8507\n",
      "Epoch 31/100\n",
      "\n",
      "Testing loss: 0.6641085743904114, acc: 0.9294670820236206\n",
      "\n",
      "54/54 - 0s - loss: 0.7143 - accuracy: 0.8636\n",
      "Epoch 32/100\n",
      "\n",
      "Testing loss: 0.671113133430481, acc: 0.9169278740882874\n",
      "\n",
      "54/54 - 0s - loss: 0.7086 - accuracy: 0.8771\n",
      "Epoch 33/100\n",
      "\n",
      "Testing loss: 0.6733101010322571, acc: 0.9184952974319458\n",
      "\n",
      "54/54 - 0s - loss: 0.7074 - accuracy: 0.8765\n",
      "Epoch 34/100\n",
      "\n",
      "Testing loss: 0.6801413893699646, acc: 0.9090909361839294\n",
      "\n",
      "54/54 - 0s - loss: 0.7103 - accuracy: 0.8660\n",
      "Epoch 35/100\n",
      "\n",
      "Testing loss: 0.6605676412582397, acc: 0.9341692924499512\n",
      "\n",
      "54/54 - 0s - loss: 0.7072 - accuracy: 0.8665\n",
      "Epoch 36/100\n",
      "\n",
      "Testing loss: 0.670233428478241, acc: 0.9278996586799622\n",
      "\n",
      "54/54 - 0s - loss: 0.7036 - accuracy: 0.8789\n",
      "Epoch 37/100\n",
      "\n",
      "Testing loss: 0.6842572689056396, acc: 0.9137930870056152\n",
      "\n",
      "54/54 - 0s - loss: 0.7130 - accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "\n",
      "Testing loss: 0.6602351665496826, acc: 0.931034505367279\n",
      "\n",
      "54/54 - 0s - loss: 0.7075 - accuracy: 0.8701\n",
      "Epoch 39/100\n",
      "\n",
      "Testing loss: 0.6513180136680603, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.7026 - accuracy: 0.8789\n",
      "Epoch 40/100\n",
      "\n",
      "Testing loss: 0.6457616090774536, acc: 0.945141077041626\n",
      "\n",
      "54/54 - 0s - loss: 0.7038 - accuracy: 0.8718\n",
      "Epoch 41/100\n",
      "\n",
      "Testing loss: 0.6842350959777832, acc: 0.9200627207756042\n",
      "\n",
      "54/54 - 0s - loss: 0.7039 - accuracy: 0.8748\n",
      "Epoch 42/100\n",
      "\n",
      "Testing loss: 0.6823936700820923, acc: 0.9028213024139404\n",
      "\n",
      "54/54 - 0s - loss: 0.7044 - accuracy: 0.8701\n",
      "Epoch 43/100\n",
      "\n",
      "Testing loss: 0.6854271292686462, acc: 0.9090909361839294\n",
      "\n",
      "54/54 - 0s - loss: 0.6998 - accuracy: 0.8748\n",
      "Epoch 44/100\n",
      "\n",
      "Testing loss: 0.6643015742301941, acc: 0.9278996586799622\n",
      "\n",
      "54/54 - 0s - loss: 0.7019 - accuracy: 0.8760\n",
      "Epoch 45/100\n",
      "\n",
      "Testing loss: 0.6444211602210999, acc: 0.9420062899589539\n",
      "\n",
      "54/54 - 0s - loss: 0.7038 - accuracy: 0.8683\n",
      "Epoch 46/100\n",
      "\n",
      "Testing loss: 0.6623103618621826, acc: 0.9216300845146179\n",
      "\n",
      "54/54 - 0s - loss: 0.7009 - accuracy: 0.8807\n",
      "Epoch 47/100\n",
      "\n",
      "Testing loss: 0.6644863486289978, acc: 0.9043887257575989\n",
      "\n",
      "54/54 - 0s - loss: 0.7097 - accuracy: 0.8613\n",
      "Epoch 48/100\n",
      "\n",
      "Testing loss: 0.6628908514976501, acc: 0.9216300845146179\n",
      "\n",
      "54/54 - 0s - loss: 0.7211 - accuracy: 0.8477\n",
      "Epoch 49/100\n",
      "\n",
      "Testing loss: 0.6561881303787231, acc: 0.9263322949409485\n",
      "\n",
      "54/54 - 0s - loss: 0.7031 - accuracy: 0.8724\n",
      "Epoch 50/100\n",
      "\n",
      "Testing loss: 0.6628129482269287, acc: 0.9278996586799622\n",
      "\n",
      "54/54 - 0s - loss: 0.7034 - accuracy: 0.8677\n",
      "Epoch 51/100\n",
      "\n",
      "Testing loss: 0.641880452632904, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.6994 - accuracy: 0.8783\n",
      "Epoch 52/100\n",
      "\n",
      "Testing loss: 0.655376672744751, acc: 0.931034505367279\n",
      "\n",
      "54/54 - 0s - loss: 0.7040 - accuracy: 0.8765\n",
      "Epoch 53/100\n",
      "\n",
      "Testing loss: 0.7441738247871399, acc: 0.8307210206985474\n",
      "\n",
      "54/54 - 0s - loss: 0.7013 - accuracy: 0.8748\n",
      "Epoch 54/100\n",
      "\n",
      "Testing loss: 0.6635547280311584, acc: 0.9294670820236206\n",
      "\n",
      "54/54 - 0s - loss: 0.7000 - accuracy: 0.8777\n",
      "Epoch 55/100\n",
      "\n",
      "Testing loss: 0.687340497970581, acc: 0.9059560894966125\n",
      "\n",
      "54/54 - 0s - loss: 0.6981 - accuracy: 0.8771\n",
      "Epoch 56/100\n",
      "\n",
      "Testing loss: 0.6360731720924377, acc: 0.9467084407806396\n",
      "\n",
      "54/54 - 0s - loss: 0.7018 - accuracy: 0.8783\n",
      "Epoch 57/100\n",
      "\n",
      "Testing loss: 0.6765244007110596, acc: 0.9090909361839294\n",
      "\n",
      "54/54 - 0s - loss: 0.6953 - accuracy: 0.8830\n",
      "Epoch 58/100\n",
      "\n",
      "Testing loss: 0.6754897236824036, acc: 0.907523512840271\n",
      "\n",
      "54/54 - 0s - loss: 0.6976 - accuracy: 0.8771\n",
      "Epoch 59/100\n",
      "\n",
      "Testing loss: 0.641670286655426, acc: 0.9388715028762817\n",
      "\n",
      "54/54 - 0s - loss: 0.6964 - accuracy: 0.8783\n",
      "Epoch 60/100\n",
      "\n",
      "Testing loss: 0.633845865726471, acc: 0.9482758641242981\n",
      "\n",
      "54/54 - 0s - loss: 0.7014 - accuracy: 0.8742\n",
      "Epoch 61/100\n",
      "\n",
      "Testing loss: 0.6778185367584229, acc: 0.9106582999229431\n",
      "\n",
      "54/54 - 0s - loss: 0.7024 - accuracy: 0.8742\n",
      "Epoch 62/100\n",
      "\n",
      "Testing loss: 0.6844756603240967, acc: 0.9122257232666016\n",
      "\n",
      "54/54 - 0s - loss: 0.6969 - accuracy: 0.8824\n",
      "Epoch 63/100\n",
      "\n",
      "Testing loss: 0.6472602486610413, acc: 0.9373040795326233\n",
      "\n",
      "54/54 - 0s - loss: 0.7046 - accuracy: 0.8707\n",
      "Epoch 64/100\n",
      "\n",
      "Testing loss: 0.6454929113388062, acc: 0.9326018691062927\n",
      "\n",
      "54/54 - 0s - loss: 0.6971 - accuracy: 0.8742\n",
      "Epoch 65/100\n",
      "\n",
      "Testing loss: 0.6589508652687073, acc: 0.92476487159729\n",
      "\n",
      "54/54 - 0s - loss: 0.6978 - accuracy: 0.8783\n",
      "Epoch 66/100\n",
      "\n",
      "Testing loss: 0.6494747996330261, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.6989 - accuracy: 0.8789\n",
      "Epoch 67/100\n",
      "\n",
      "Testing loss: 0.6642550230026245, acc: 0.92476487159729\n",
      "\n",
      "54/54 - 0s - loss: 0.6992 - accuracy: 0.8677\n",
      "Epoch 68/100\n",
      "\n",
      "Testing loss: 0.6945956945419312, acc: 0.8824451565742493\n",
      "\n",
      "54/54 - 0s - loss: 0.6947 - accuracy: 0.8830\n",
      "Epoch 69/100\n",
      "\n",
      "Testing loss: 0.6724331378936768, acc: 0.9122257232666016\n",
      "\n",
      "54/54 - 0s - loss: 0.6995 - accuracy: 0.8701\n",
      "Epoch 70/100\n",
      "\n",
      "Testing loss: 0.6551203727722168, acc: 0.9341692924499512\n",
      "\n",
      "54/54 - 0s - loss: 0.6986 - accuracy: 0.8748\n",
      "Epoch 71/100\n",
      "\n",
      "Testing loss: 0.6416826248168945, acc: 0.9404388666152954\n",
      "\n",
      "54/54 - 0s - loss: 0.6950 - accuracy: 0.8795\n",
      "Epoch 72/100\n",
      "\n",
      "Testing loss: 0.650489091873169, acc: 0.9294670820236206\n",
      "\n",
      "54/54 - 0s - loss: 0.6933 - accuracy: 0.8871\n",
      "Epoch 73/100\n",
      "\n",
      "Testing loss: 0.6540514826774597, acc: 0.9294670820236206\n",
      "\n",
      "54/54 - 0s - loss: 0.6982 - accuracy: 0.8754\n",
      "Epoch 74/100\n",
      "\n",
      "Testing loss: 0.6562626957893372, acc: 0.9278996586799622\n",
      "\n",
      "54/54 - 0s - loss: 0.6963 - accuracy: 0.8760\n",
      "Epoch 75/100\n",
      "\n",
      "Testing loss: 0.6303411722183228, acc: 0.9514106512069702\n",
      "\n",
      "54/54 - 0s - loss: 0.6939 - accuracy: 0.8765\n",
      "Epoch 76/100\n",
      "\n",
      "Testing loss: 0.6545737981796265, acc: 0.9357366561889648\n",
      "\n",
      "54/54 - 0s - loss: 0.6982 - accuracy: 0.8736\n",
      "Epoch 77/100\n",
      "\n",
      "Testing loss: 0.6325670480728149, acc: 0.945141077041626\n",
      "\n",
      "54/54 - 0s - loss: 0.6998 - accuracy: 0.8718\n",
      "Epoch 78/100\n",
      "\n",
      "Testing loss: 0.702778697013855, acc: 0.8746081590652466\n",
      "\n",
      "54/54 - 0s - loss: 0.6931 - accuracy: 0.8765\n",
      "Epoch 79/100\n",
      "\n",
      "Testing loss: 0.6422958374023438, acc: 0.9420062899589539\n",
      "\n",
      "54/54 - 0s - loss: 0.7022 - accuracy: 0.8654\n",
      "Epoch 80/100\n",
      "\n",
      "Testing loss: 0.6472303867340088, acc: 0.9357366561889648\n",
      "\n",
      "54/54 - 0s - loss: 0.6966 - accuracy: 0.8724\n",
      "Epoch 81/100\n",
      "\n",
      "Testing loss: 0.6583390831947327, acc: 0.9294670820236206\n",
      "\n",
      "54/54 - 0s - loss: 0.6904 - accuracy: 0.8854\n",
      "Epoch 82/100\n",
      "\n",
      "Testing loss: 0.6747990846633911, acc: 0.9059560894966125\n",
      "\n",
      "54/54 - 0s - loss: 0.6936 - accuracy: 0.8777\n",
      "Epoch 83/100\n",
      "\n",
      "Testing loss: 0.6448162794113159, acc: 0.9357366561889648\n",
      "\n",
      "54/54 - 0s - loss: 0.6998 - accuracy: 0.8701\n",
      "Epoch 84/100\n",
      "\n",
      "Testing loss: 0.6476560831069946, acc: 0.9357366561889648\n",
      "\n",
      "54/54 - 0s - loss: 0.6955 - accuracy: 0.8765\n",
      "Epoch 85/100\n",
      "\n",
      "Testing loss: 0.6388081312179565, acc: 0.9388715028762817\n",
      "\n",
      "54/54 - 0s - loss: 0.6932 - accuracy: 0.8807\n",
      "Epoch 86/100\n",
      "\n",
      "Testing loss: 0.6646782755851746, acc: 0.9216300845146179\n",
      "\n",
      "54/54 - 0s - loss: 0.6924 - accuracy: 0.8795\n",
      "Epoch 87/100\n",
      "\n",
      "Testing loss: 0.6433131694793701, acc: 0.9388715028762817\n",
      "\n",
      "54/54 - 0s - loss: 0.6998 - accuracy: 0.8742\n",
      "Epoch 88/100\n",
      "\n",
      "Testing loss: 0.6338801383972168, acc: 0.9420062899589539\n",
      "\n",
      "54/54 - 0s - loss: 0.6949 - accuracy: 0.8771\n",
      "Epoch 89/100\n",
      "\n",
      "Testing loss: 0.7461981177330017, acc: 0.8228840231895447\n",
      "\n",
      "54/54 - 0s - loss: 0.6900 - accuracy: 0.8865\n",
      "Epoch 90/100\n",
      "\n",
      "Testing loss: 0.6667674779891968, acc: 0.9169278740882874\n",
      "\n",
      "54/54 - 0s - loss: 0.6983 - accuracy: 0.8801\n",
      "Epoch 91/100\n",
      "\n",
      "Testing loss: 0.6266414523124695, acc: 0.9514106512069702\n",
      "\n",
      "54/54 - 0s - loss: 0.6984 - accuracy: 0.8760\n",
      "Epoch 92/100\n",
      "\n",
      "Testing loss: 0.6899498701095581, acc: 0.8918495178222656\n",
      "\n",
      "54/54 - 0s - loss: 0.6964 - accuracy: 0.8736\n",
      "Epoch 93/100\n",
      "\n",
      "Testing loss: 0.6767998337745667, acc: 0.8981191515922546\n",
      "\n",
      "54/54 - 0s - loss: 0.6977 - accuracy: 0.8730\n",
      "Epoch 94/100\n",
      "\n",
      "Testing loss: 0.6333820223808289, acc: 0.9498432874679565\n",
      "\n",
      "54/54 - 0s - loss: 0.6895 - accuracy: 0.8836\n",
      "Epoch 95/100\n",
      "\n",
      "Testing loss: 0.6328300833702087, acc: 0.9482758641242981\n",
      "\n",
      "54/54 - 0s - loss: 0.6918 - accuracy: 0.8812\n",
      "Epoch 96/100\n",
      "\n",
      "Testing loss: 0.6455786824226379, acc: 0.9357366561889648\n",
      "\n",
      "54/54 - 0s - loss: 0.6930 - accuracy: 0.8801\n",
      "Epoch 97/100\n",
      "\n",
      "Testing loss: 0.6753018498420715, acc: 0.8996865153312683\n",
      "\n",
      "54/54 - 0s - loss: 0.6903 - accuracy: 0.8789\n",
      "Epoch 98/100\n",
      "\n",
      "Testing loss: 0.6324544548988342, acc: 0.9435736536979675\n",
      "\n",
      "54/54 - 0s - loss: 0.7014 - accuracy: 0.8683\n",
      "Epoch 99/100\n",
      "\n",
      "Testing loss: 0.6590832471847534, acc: 0.9200627207756042\n",
      "\n",
      "54/54 - 0s - loss: 0.6922 - accuracy: 0.8771\n",
      "Epoch 100/100\n",
      "\n",
      "Testing loss: 0.6506718993186951, acc: 0.9169278740882874\n",
      "\n",
      "54/54 - 0s - loss: 0.6886 - accuracy: 0.8789\n",
      "14/14 - 0s - loss: 0.6664 - accuracy: 0.9012\n",
      "processing fold # 4\n",
      "Epoch 1/100\n",
      "\n",
      "Testing loss: 0.7440518736839294, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.8871 - accuracy: 0.7537\n",
      "Epoch 2/100\n",
      "\n",
      "Testing loss: 0.7238726615905762, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7924 - accuracy: 0.7737\n",
      "Epoch 3/100\n",
      "\n",
      "Testing loss: 0.7193501591682434, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7814 - accuracy: 0.7737\n",
      "Epoch 4/100\n",
      "\n",
      "Testing loss: 0.7181873917579651, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7787 - accuracy: 0.7737\n",
      "Epoch 5/100\n",
      "\n",
      "Testing loss: 0.717858076095581, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7781 - accuracy: 0.7737\n",
      "Epoch 6/100\n",
      "\n",
      "Testing loss: 0.7177403569221497, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7779 - accuracy: 0.7737\n",
      "Epoch 7/100\n",
      "\n",
      "Testing loss: 0.7176834940910339, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7779 - accuracy: 0.7737\n",
      "Epoch 8/100\n",
      "\n",
      "Testing loss: 0.7176547050476074, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 9/100\n",
      "\n",
      "Testing loss: 0.7176374793052673, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 10/100\n",
      "\n",
      "Testing loss: 0.7176266312599182, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 11/100\n",
      "\n",
      "Testing loss: 0.717619001865387, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 12/100\n",
      "\n",
      "Testing loss: 0.7176136374473572, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 13/100\n",
      "\n",
      "Testing loss: 0.7176097631454468, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 14/100\n",
      "\n",
      "Testing loss: 0.7176064252853394, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 15/100\n",
      "\n",
      "Testing loss: 0.7176039814949036, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 16/100\n",
      "\n",
      "Testing loss: 0.7176020741462708, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 17/100\n",
      "\n",
      "Testing loss: 0.717600405216217, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 18/100\n",
      "\n",
      "Testing loss: 0.7175991535186768, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 19/100\n",
      "\n",
      "Testing loss: 0.7175981998443604, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 20/100\n",
      "\n",
      "Testing loss: 0.7175973057746887, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 21/100\n",
      "\n",
      "Testing loss: 0.7175964713096619, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 22/100\n",
      "\n",
      "Testing loss: 0.7175956964492798, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 23/100\n",
      "\n",
      "Testing loss: 0.7175951600074768, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 24/100\n",
      "\n",
      "Testing loss: 0.717594563961029, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 25/100\n",
      "\n",
      "Testing loss: 0.7175940871238708, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 26/100\n",
      "\n",
      "Testing loss: 0.7175936698913574, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 27/100\n",
      "\n",
      "Testing loss: 0.7175933122634888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 28/100\n",
      "\n",
      "Testing loss: 0.7175930738449097, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 29/100\n",
      "\n",
      "Testing loss: 0.7175926566123962, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 30/100\n",
      "\n",
      "Testing loss: 0.7175924181938171, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 31/100\n",
      "\n",
      "Testing loss: 0.7175921201705933, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 32/100\n",
      "\n",
      "Testing loss: 0.7175918817520142, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 33/100\n",
      "\n",
      "Testing loss: 0.7175918221473694, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 34/100\n",
      "\n",
      "Testing loss: 0.7175916433334351, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 35/100\n",
      "\n",
      "Testing loss: 0.7175914645195007, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 36/100\n",
      "\n",
      "Testing loss: 0.7175913453102112, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 37/100\n",
      "\n",
      "Testing loss: 0.7175911664962769, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 38/100\n",
      "\n",
      "Testing loss: 0.7175909876823425, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 39/100\n",
      "\n",
      "Testing loss: 0.7175909280776978, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 40/100\n",
      "\n",
      "Testing loss: 0.7175909280776978, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 41/100\n",
      "\n",
      "Testing loss: 0.7175906300544739, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 42/100\n",
      "\n",
      "Testing loss: 0.7175905704498291, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 43/100\n",
      "\n",
      "Testing loss: 0.7175905108451843, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 44/100\n",
      "\n",
      "Testing loss: 0.7175903916358948, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 45/100\n",
      "\n",
      "Testing loss: 0.7175903916358948, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 46/100\n",
      "\n",
      "Testing loss: 0.71759033203125, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 47/100\n",
      "\n",
      "Testing loss: 0.71759033203125, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 48/100\n",
      "\n",
      "Testing loss: 0.7175901532173157, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 49/100\n",
      "\n",
      "Testing loss: 0.7175900340080261, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 50/100\n",
      "\n",
      "Testing loss: 0.7175900340080261, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 51/100\n",
      "\n",
      "Testing loss: 0.7175900340080261, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 52/100\n",
      "\n",
      "Testing loss: 0.7175899744033813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 53/100\n",
      "\n",
      "Testing loss: 0.7175899744033813, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 54/100\n",
      "\n",
      "Testing loss: 0.717589795589447, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 55/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 56/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 57/100\n",
      "\n",
      "Testing loss: 0.7175898551940918, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 58/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 59/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 60/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 61/100\n",
      "\n",
      "Testing loss: 0.7175897359848022, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 62/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 63/100\n",
      "\n",
      "Testing loss: 0.7175896167755127, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 64/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 65/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 66/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 67/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 68/100\n",
      "\n",
      "Testing loss: 0.7175894975662231, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 69/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 70/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 71/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 72/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 73/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 74/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 75/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 76/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 77/100\n",
      "\n",
      "Testing loss: 0.7175893187522888, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 78/100\n",
      "\n",
      "Testing loss: 0.717589259147644, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 79/100\n",
      "\n",
      "Testing loss: 0.717589259147644, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 80/100\n",
      "\n",
      "Testing loss: 0.717589259147644, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 81/100\n",
      "\n",
      "Testing loss: 0.717589259147644, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 82/100\n",
      "\n",
      "Testing loss: 0.717589259147644, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 83/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 84/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 85/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 86/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 87/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 88/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 89/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 90/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 91/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 92/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 93/100\n",
      "\n",
      "Testing loss: 0.7175891995429993, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 94/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 95/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 96/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 97/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 98/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 99/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "Epoch 100/100\n",
      "\n",
      "Testing loss: 0.7175891399383545, acc: 0.8338558077812195\n",
      "\n",
      "54/54 - 0s - loss: 0.7778 - accuracy: 0.7737\n",
      "14/14 - 0s - loss: 0.7538 - accuracy: 0.7976\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # prepare validation data: the data from k-th set\n",
    "    validation_data = trainX[i * num_val_samples: (i+1)*num_val_samples]\n",
    "    validation_targets = trainY[i * num_val_samples: (i+1)*num_val_samples]\n",
    "    \n",
    "    # prepare training data: all the data except k-th set\n",
    "    partial_train_data = np.concatenate(\n",
    "        [trainX[:i * num_val_samples],\n",
    "         trainX[(i + 1) * num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    partial_train_target = np.concatenate(\n",
    "        [trainY[:i * num_val_samples],\n",
    "         trainY[(i + 1) * num_val_samples:]],\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    # create the model\n",
    "    model = build_model()\n",
    "    \n",
    "    # train the model \n",
    "    history = model.fit(partial_train_data, partial_train_target,\n",
    "                                        epochs=epochs,\n",
    "                                        verbose = 2,\n",
    "                                        batch_size=batch_size,\n",
    "                        callbacks=[TestCallback((X_test, y_test))])\n",
    "    \n",
    "    acc_history = history.history['accuracy']\n",
    "    histories_acc.append(acc_history)\n",
    "    \n",
    "    loss_history = history.history['loss']\n",
    "    histories_loss.append(loss_history)\n",
    "    \n",
    "    # evaluate the model on validation_data\n",
    "    score = model.evaluate(validation_data, validation_targets, verbose=2)\n",
    "    all_scores.append(score) # should have 5 histories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['loss', 'accuracy'])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "history.history.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.9749742746353149, 0.5764706134796143], [0.8949742913246155, 0.6564705967903137], [0.5726224184036255, 0.9788235425949097], [0.6663742065429688, 0.9011764526367188], [0.7537978887557983, 0.7976470589637756]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(all_scores) # validation loss; validation accuracy for each 5 folders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "average_acc_history = [\n",
    "    np.mean([x[i] for x in histories_acc]) for i in range(epochs)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(average_acc_history) + 1), average_acc_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation acccuracy')\n",
    "plt.savefig('result.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "20/20 [==============================] - 0s 530us/step - loss: 0.7176 - accuracy: 0.8339\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7175891399383545"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8338558077812195"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}